Prepare your final project
Project Overview ü¶Å
1200 min
Objective:

Your task is to develop a fully functional MLOps pipeline that automates the entire lifecycle of a machine learning model. You will start by finding your own dataset, train a model, and then build the infrastructure needed for deployment, monitoring, continuous training, and more.

This project will test your ability to independently manage the full spectrum of data science and machine learning operations, focusing on building a scalable, automated pipeline that works in real-world scenarios.
Project Overview
1. Find Your Dataset and Prepare the Data

You are responsible for finding a dataset that is both challenging and relevant to a real-world problem. This can come from any publicly available source, or you can collect the data yourself. The dataset should be complex enough to challenge your skills in model training and MLOps implementation.

Once you have the data, you‚Äôll need to clean and preprocess it. This includes handling missing values, dealing with outliers, and balancing the data as needed. Think about feature engineering to maximize model performance.
2. Model Training

You‚Äôll need to train a machine learning model based on the dataset you chose. Select a relevant algorithm based on the problem you are trying to solve (e.g., classification, regression, clustering). Use frameworks like TensorFlow, PyTorch, or Scikit-learn to train and evaluate your model.

    Justify the choice of your algorithm.
    Tune hyperparameters to optimize the model‚Äôs performance.
    Evaluate the model using appropriate metrics (e.g., accuracy, precision, recall, F1-score, etc.).

Your model should be robust and ready for real-world deployment.
3. Build an MLOps Pipeline

Now comes the main challenge: building a pipeline that can automate the process of training, deploying, monitoring, and retraining the model. Here‚Äôs what you‚Äôll need to do:
a. Model Deployment

Deploy the model using Docker or Kubernetes, and make it available via a REST API. Your deployment should be scalable, capable of handling real-time data and requests. You can choose cloud platforms like AWS, Google Cloud, or Azure, or work on-premise.
b. Continuous Integration and Continuous Deployment (CI/CD)

Automate the model deployment process using CI/CD tools like GitHub Actions, GitLab CI, or Jenkins. Set up automated testing, validation, and deployment pipelines that trigger whenever the model is updated.
c. Monitoring and Logging

Implement tools like Aporia or Evidently to monitor your model in production. This includes tracking metrics like latency, accuracy, and drift detection. Ensure that your model stays within performance standards, and set up alerts for when it drifts or its accuracy falls below a certain threshold.
d. Automated Model Retraining

Create a retraining pipeline that automatically kicks in when the performance metrics indicate model drift or when new data becomes available. Use tools like Apache Airflow or Kubeflow to automate the process, ensuring that the model gets updated seamlessly.
e. Versioning and Rollback

Use tools like DVC or MLflow to handle data and model versioning. You should be able to roll back to a previous version of your model if the new one doesn‚Äôt perform as expected.
f. API Development and Documentation

Develop APIs for interacting with your deployed model. Make sure your APIs are well-documented, clearly explaining the inputs, outputs, and usage for others to integrate.
What to Submit

    Dataset and Preprocessing Report: Clearly explain the dataset you chose, how you preprocessed it, and the reasoning behind your data transformations.
    Trained Model Notebook or Script: A notebook or script showing how you trained and evaluated your model, including hyperparameter tuning and final performance metrics.
    MLOps Pipeline:
        A diagram of your MLOps pipeline architecture.
        Code for deploying the model, setting up CI/CD, monitoring, and retraining.
        A video walkthrough or screenshots demonstrating the pipeline in action.
    Code Repository: Upload your code to a GitHub repository, complete with clear instructions on how to run and deploy the pipeline.
    API Documentation: A clear and concise API guide for interacting with the deployed model.
    A Presentation: For when you present in front of your class or the jury

Key Evaluation Criteria

    Data Preparation and Model Performance: Did you select a meaningful dataset, preprocess it properly, and train a high-performance model?
    Pipeline Completeness: Does your MLOps pipeline handle the entire lifecycle from deployment to monitoring and retraining?
    Automation: How well have you automated the processes for deployment and retraining? Is the system robust enough to handle changes in data or performance?
    Scalability and Monitoring: Can your pipeline scale to handle larger data volumes and heavier user loads? Is the monitoring system proactive and effective?
    Documentation and Usability: Is the pipeline clearly documented and accessible for future developers or stakeholders?
